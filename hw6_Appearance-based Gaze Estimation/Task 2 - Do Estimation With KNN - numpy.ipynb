{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Appearance-based gaze estimation - Task 02\n",
    "\n",
    "Author: `Yintao, Xu` | Date: `2020-02-13 ~ 2020-02-15` | Email: xuyt@shanghaitech.edu.cn\n",
    "\n",
    "Topics: `numpy`\n",
    "\n",
    "**Note**: Make sure you have completed `task 01 - pandas notebook`, or you will find this notebook is a little bit challenging!\n",
    "\n",
    "In this section, we will build a gaze estimation system by KNN(K-nearest neighbour).\n",
    "\n",
    "![](figures/gaze_model_pipeline.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: run this cell before runnng any cell to activate auto re-import\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# 'gazelib' is the toolkit provided by this assignment, at the same directory of this notebook\n",
    "from gazelib.utils import *\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets has been supposed to be downloaded at last notebook\n",
    "# You could run thie cell to have a check :)\n",
    "download_csv_mpIIdataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training dataset\n",
    "train_df = load_train_csv_as_df()\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of the yaw and pitch\n",
    "vis.vis_yaw_pitch(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, first, split our dataset(`np_imgs`, `np_gaze_dirs`) into `training set` and `validation set`.\n",
    "\n",
    "- `Training Dataset`: The sample of data used to generate the model or provide knowledge base for model.\n",
    "- `Validation Dataset`: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset at our design process. We could test performance of model on this set.\n",
    "- `Test Dataset`: Other people will judge the performance of your model at their test dataset. The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "\n",
    "\n",
    "![](figures/train_val_test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data into numpy arrays\n",
    "def df2nptensor(df):\n",
    "    imgs = []\n",
    "    imgs_HOG = []\n",
    "    gaze_dirs = []\n",
    "\n",
    "    print_interval = 1000\n",
    "    print_cnter = 0\n",
    "    \n",
    "    for _, i in df.iterrows():\n",
    "        if print_cnter % print_interval == 0:\n",
    "            print(\"[{} / {}]\".format(print_cnter, len(df)), end='\\r')\n",
    "        print_cnter += 1\n",
    "        im_arr = decode_base64_img(i['image_base64'])\n",
    "        gaze_dirs.append([i['yaw'], i['pitch']])\n",
    "        im = im_arr / 255\n",
    "        \n",
    "        imgs.append(im)\n",
    "    \n",
    "    gaze_dirs = np.array(gaze_dirs)\n",
    "    imgs = np.array(imgs)\n",
    "    \n",
    "    return gaze_dirs, imgs\n",
    "\n",
    "# For effciency, we only takes first 5,000 samples. Pick subject 5 as validation \n",
    "# set and the rest of the dataset as training set\n",
    "SAMPLE_NUM = 5000\n",
    "print(\"Start to generate sampled dataset, it may take ~10s.\")\n",
    "train_Y, train_X = df2nptensor(train_df[train_df[\"subject_id\"] != 5][: int(SAMPLE_NUM * 0.8)])\n",
    "val_Y, val_X = df2nptensor(train_df[train_df[\"subject_id\"] == 5][: int(SAMPLE_NUM * 0.2)])\n",
    "\n",
    "print(\"train_X.shape: {}\".format(train_X.shape))\n",
    "print(\"train_Y.shape: {}\".format(train_Y.shape))\n",
    "print(\"val_X.shape: {}\".format(val_X.shape))\n",
    "print(\"val_X.shape: {}\".format(val_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulize an image (randomly sampled one, you could repeatedly run this cell)\n",
    "plt.imshow(train_X[random.randint(0, train_X.shape[0])], vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.title(\"Eye image\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.0: Eye Search Engine\n",
    "\n",
    "In this section, we aim at finding an eye in the database by Euclidean distances between image arrays.\n",
    "\n",
    "$$\n",
    "    d = \\sqrt{\\sum_i \\sum_j ( I_{ij}^a - I_{ij}^b )_2}\n",
    "$$\n",
    "\n",
    "**Example:** Here is an example of computing Euclidean distance between two images.\n",
    "\n",
    "You could repeatedly run following cells to see distance between different image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compute Euclidean distance of two images\n",
    "# randomly sample image pair\n",
    "idx_a, idx_b = random.randint(0, train_X.shape[0]), random.randint(0, train_X.shape[0])\n",
    "image_a = train_X[idx_a]\n",
    "image_b = train_X[idx_b]\n",
    "\n",
    "# compute Euclidean distance by taking norm 2\n",
    "dist = np.linalg.norm(image_a - image_b)\n",
    "\n",
    "# visualize\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_a, vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Index a: {}\".format(idx_a))\n",
    "plt.subplot(122)\n",
    "plt.imshow(image_b, vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Index b: {}\".format(idx_b))\n",
    "\n",
    "print(\"Euclidean distance: {:.3f}\".format(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.0.2: K-top Eye Search Engine (10%)\n",
    "\n",
    "In this section, you are required to implement a simple eye search engine. It is defined as follows: for each sample in validation set, find k samples in training set with most simlarity(sorted from the highest simlarity to the lowest). The simlarity is evalauted by Euclidean distance as mentioned above. \n",
    "\n",
    "**Algorithm**:\n",
    "- Compute Euclidean distance(norm-2) from the `val_x` to each element in `train_X`.\n",
    "- Sort by Euclidean distances.\n",
    "- Return the first k indices of elements ascendingly.\n",
    "\n",
    "You could start from more intuitive 2D cases, then generalize your algorithm to the cases of images. \n",
    "\n",
    "Plus, for arrays, each sample is indexed by the first dimension. For example, in 2D cases, each row in a matrix is a sample point.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "- train_X = [[0, 0], [1, 1], [2.5, 2.5], [3.5, 3.5]]\n",
    "- val_x = [2, 2]\n",
    "- KNN_idx(train_X, val_x, 4) -> [2, 1, 3, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/code_time.png)\n",
    "**Complete code at `AppearanceGazeEst.py/KNN_idxs`(10%)**\n",
    "\n",
    "**Hint**: `np.argsort`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Test 1 - Toy data\n",
    "# Note: feel free to print out your result to debug if it cannot pass assert_eq_np\n",
    "from AppearanceGazeEst import KNN_idxs\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "sanity_trainX =  np.array([[0, 0], [1, 1], [2.5, 2.5], [3.5, 3.5]])\n",
    "sanity_valX=  np.array([2, 2])\n",
    "\n",
    "ret = KNN_idxs(sanity_trainX, sanity_valX, 100)\n",
    "\n",
    "assert_eq_np(ret, np.array([2, 1, 3, 0]))\n",
    "print(\"Pass local test 1@2.0.2 - toy data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Test 2 - Eye images\n",
    "# Note: feel free to print out your result to debug if it cannot pass assert_eq_np\n",
    "from AppearanceGazeEst import KNN_idxs\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "# pick the second image at validation set and find four images at training set with most simlarity\n",
    "idx = 10\n",
    "ret = KNN_idxs(train_X, val_X[idx], 4)\n",
    "print(ret)\n",
    "assert_eq_np(ret, np.array([3453,  604, 1817, 3645]))\n",
    "print(\"Pass local test 2@2.0.2 - eye images\")\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(151)\n",
    "plt.imshow(val_X[idx] , vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.title(\"Image[4]@Val.\")\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(152 + i)\n",
    "    plt.imshow(train_X[ret[i]] , vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.title(\"Image[{}]@Tr.\".format(ret[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playground\n",
    "from AppearanceGazeEst import KNN_idxs\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "rdn_idx = random.randint(0, val_X.shape[0])\n",
    "ret = KNN_idxs(train_X, val_X[rdn_idx], 4)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(151)\n",
    "plt.imshow(val_X[rdn_idx] , vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.title(\"Image[4]@Val.\")\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(152 + i)\n",
    "    plt.imshow(train_X[ret[i]] , vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.title(\"Image[{}]@Tr.\".format(ret[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1: From Search Engine To A Baseline Estimator - 1-NN estimator (5%)\n",
    "\n",
    "At previous sections, we built a search engine of eye images. In fact, by simply injecting lines of code at previous process, the \"search engine\" could be converted into a gaze estimator.\n",
    "\n",
    "![](figures/1_NN_new.png)\n",
    "\n",
    "- Compute the Euclidean distance from the query example(`val_x`) to the labeled examples.\n",
    "- Find the image with the most simlarity(one image in `train_X` with the nearest Euclidean distance).\n",
    "- Take its corresponding label as output(`train_Y[min_idx]`).\n",
    "\n",
    "You could start from more intuitive 2D case, then generalize your algorithm to the case of images. Intuitively, it takes the label of the nearest sample as output. Therefore, it is called \"one nearest neighbour\".\n",
    "\n",
    "**Example(2D Case)**:\n",
    "- `train_X` = [[0, 0], [1, 1], [2.5, 2.5], [3.5, 3.5]]\n",
    "- `train_Y` = [[20], [30], [40], [50]]\n",
    "- `val_x` = [2, 2]\n",
    "- `KNN_idx(train_X, val_x, 1)` -> [2]\n",
    "- `oneNN(train_X, train_Y, val_x)` -> `train_Y[2]` <-> [40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/code_time.png)\n",
    "**Complete code at `AppearanceGazeEst.py/oneNN`(5%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Test 1 - Toy data\n",
    "# Note: feel free to print out your result to debug if it cannot pass assert_eq_np\n",
    "from AppearanceGazeEst import oneNN\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "sanity_trainX = np.array([[0, 0], [1, 1], [2.5, 2.5], [3.5, 3.5]])\n",
    "sanity_trainY = np.array([[20], [30], [40], [50]])\n",
    "sanity_valX=  np.array([2, 2])\n",
    "\n",
    "ret = oneNN(sanity_trainX, sanity_trainY, sanity_valX)\n",
    "\n",
    "assert_eq_np(ret, 40)\n",
    "print(\"Pass local test 1@2.1 - toy data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Test 2 - Eye images\n",
    "# Note: feel free to print out your result to debug if it cannot pass assert_eq_np\n",
    "from AppearanceGazeEst import oneNN\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "from gazelib.task_3_judge import compute_angle_error\n",
    "\n",
    "idx = 10\n",
    "ret = oneNN(train_X, train_Y, val_X[idx])\n",
    "assert_eq_np(ret, np.array([ 0.1283756,  -0.09948426]))\n",
    "\n",
    "print(\"Pass local test 2@2.1 - eye images\")\n",
    "plt.figure(figsize=(4, 3))\n",
    "vis.visualize_est(val_X[idx], ret, val_Y[idx])\n",
    "plt.title(\"Angle Error: {:.3f} degree\".format(compute_angle_error(val_Y[idx], ret)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playground\n",
    "from AppearanceGazeEst import oneNN\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    plt.subplot(231 + i)\n",
    "    random_idx = random.randint(0, val_X.shape[0])\n",
    "    ret = oneNN(train_X, train_Y, val_X[random_idx])\n",
    "\n",
    "    vis.visualize_est(val_X[random_idx], ret, val_Y[random_idx])\n",
    "    plt.title(\"Angle Error: {:.3f} degree\".format(compute_angle_error(val_Y[random_idx], ret)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2: From  1-NN estimator to K-NN estimator (5%)\n",
    "\n",
    "For the 1-NN estimation of gaze, the most simlar eye is found and its gaze information is copied as output. It is also intuitive to rely on multiple samples at training set and output an average of them as the final result. Here comes the K-NN.\n",
    "\n",
    "- Compute the Euclidean distance from the query example(`val_x`) to the labeled examples.\n",
    "- Find the k images with the most simlarity(k imags in `train_X` with the nearest Euclidean distance).\n",
    "- Take the median of their corresponding labels as output.\n",
    "\n",
    "You could start from more intuitive 2D case, then generalize your algorithm to the case of images.\n",
    "\n",
    "**Example(2D Case)**:\n",
    "- `train_X` = [[0, 0], [1, 1], [2.5, 2.5], [3.5, 3.5]]\n",
    "- `train_Y` = [[20], [30], [40], [50]]\n",
    "- `val_x` = [2, 2]\n",
    "- `KNN_idx(train_X, val_x, 2)` -> [2, 1]\n",
    "- `KNN(train_X, train_Y, val_x, 2)` -> `np.mean(train_Y[[2, 1])` <-> (40 + 30) / 2 <-> 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/code_time.png)\n",
    "**Complete code at `AppearanceGazeEst.py/KNN`(5%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Test 1 - Toy data\n",
    "# Note: feel free to print out your result to debug if it cannot pass assert_eq_np\n",
    "from AppearanceGazeEst import KNN\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "sanity_trainX = np.array([[0, 0], [1, 1], [2.5, 2.5], [3.5, 3.5]])\n",
    "sanity_trainY = np.array([[20], [30], [40], [50]])\n",
    "sanity_valX=  np.array([2, 2])\n",
    "\n",
    "ret = KNN(sanity_trainX, sanity_trainY, sanity_valX, 2)\n",
    "assert_eq_np(ret, 35)\n",
    "print(\"Pass local test 1@2.2 - toy data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Test 2 - Eye images\n",
    "# Note: feel free to print out your result to debug if it cannot pass assert_eq_np\n",
    "from AppearanceGazeEst import KNN\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "from gazelib.task_3_judge import compute_angle_error\n",
    "\n",
    "idx = 10\n",
    "ret = KNN(train_X, train_Y, val_X[idx], 10)\n",
    "print(ret)\n",
    "assert_eq_np(ret, np.array([ 0.04550109, -0.05406717]))\n",
    "\n",
    "print(\"Pass local test 2@2.2 - eye images\")\n",
    "plt.figure(figsize=(4, 3))\n",
    "vis.visualize_est(val_X[idx], ret, val_Y[idx])\n",
    "plt.title(\"Angle Error: {:.3f}\".format(compute_angle_error(val_Y[idx], ret)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playground\n",
    "from AppearanceGazeEst import KNN\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    plt.subplot(231 + i)\n",
    "    random_idx = random.randint(0, val_X.shape[0])\n",
    "    ret = KNN(train_X, train_Y, val_X[random_idx], k=10)\n",
    "\n",
    "    vis.visualize_est(val_X[random_idx], ret, val_Y[random_idx])\n",
    "    plt.title(\"Angle Error: {:.3f}\".format(compute_angle_error(val_Y[random_idx], ret)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.3: K-NN Estimator With Weighted Average(15%)\n",
    "\n",
    "Naively take median of labels neglect the distance between the input and k-top instances at database. A weighted average sounds more robust.\n",
    "\n",
    "**Intuition**: Further the distance is, weaker the correlation between those two samples is.  \n",
    "\n",
    "- Compute the Euclidean distance from the query example(`val_x`) to the labeled examples.\n",
    "- Find the k images with the most simlarity(k images in `train_X` with the nearest Euclidean distance).\n",
    "- Denote the multiplicative inverse of distances as a score vector:\n",
    "\n",
    "$$\n",
    "    \\textbf{s} = [1 / d_1, 1 / d_2, \\cdots, 1 / d_k]\n",
    "$$\n",
    "\n",
    "- Denote their corresponding labels(gaze direction, a 2-d vector in this context).\n",
    "\n",
    "$$\n",
    "    \\textbf{y} = [\\textbf{y}_1, \\textbf{y}_2, \\cdots, \\textbf{y}_k]\n",
    "$$\n",
    "\n",
    "- Normalize the vector by the sum of distance.\n",
    "\n",
    "\n",
    "$$\n",
    "    \\textbf{s}_{norm} = [s_1 / \\sum_i^k s_i, s_2 / \\sum_i^k s_i, \\cdots, s_k / \\sum_i^k s_i]\n",
    "$$\n",
    "\n",
    "- Return the weighted sum.\n",
    "\n",
    "$$\n",
    "    \\textbf{o} = \\sum_{i}^{k} \\textbf{s}_{norm, i} * \\textbf{y}_{i}\n",
    "$$\n",
    "\n",
    "You could start from more intuitive 2D case, then generalize your algorithm to the case of images.\n",
    "\n",
    "**Example(2D Case)**:\n",
    "- `train_X` = [[0, 0], [1, 0], [3, 0], [4, 0]]\n",
    "- `train_Y` = [[20], [30], [40], [50]]\n",
    "- `val_x` = [2, 0]\n",
    "- `s` = [1/1, 1/1] = [1, 1]\n",
    "- `s_norm` = [0.5, 0.5]\n",
    "- `KNN_weighted(train_X, train_Y, val_x, 2)` -> `0.5 * 30 + 0.5 * 40` <-> 35\n",
    "\n",
    "![](figures/code_time.png)\n",
    "**Complete code at `AppearanceGazeEst.py/KNN_weighted`(15%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Test 1 - Toy data\n",
    "# Note: feel free to print out your result to debug if it cannot pass assert_eq_np\n",
    "from AppearanceGazeEst import KNN_weighted\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "sanity_trainX = np.array([[0, 0], [1, 0], [3, 0], [4, 0]])\n",
    "sanity_trainY = np.array([[20], [30], [40], [50]])\n",
    "sanity_valX=  np.array([2, 0])\n",
    "\n",
    "ret = KNN_weighted(sanity_trainX, sanity_trainY, sanity_valX, 2)\n",
    "print(ret)\n",
    "assert_eq_np(ret, 35)\n",
    "print(\"Pass local test 1@2.3 - toy data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Test 2 - Eye images\n",
    "# Note: feel free to print out your result to debug if it cannot pass assert_eq_np\n",
    "from AppearanceGazeEst import KNN_weighted\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "from gazelib.task_3_judge import compute_angle_error\n",
    "\n",
    "idx = 10\n",
    "ret = KNN_weighted(train_X, train_Y, val_X[idx], 5)\n",
    "print(ret)\n",
    "assert_eq_np(ret, np.array([0.08485499, -0.0870907 ]))\n",
    "\n",
    "print(\"Pass local test 2@2.3 - eye images\")\n",
    "plt.figure(figsize=(4, 3))\n",
    "vis.visualize_est(val_X[idx], ret, val_Y[idx])\n",
    "plt.title(\"Angle Error: {:.3f}\".format(compute_angle_error(val_Y[idx], ret)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playground\n",
    "from AppearanceGazeEst import KNN_weighted\n",
    "from gazelib.task_2_judge import assert_eq_np\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    plt.subplot(231 + i)\n",
    "    random_idx = random.randint(0, val_X.shape[0])\n",
    "    ret = KNN_weighted(train_X, train_Y, val_X[random_idx], k=10)\n",
    "\n",
    "    vis.visualize_est(val_X[random_idx], ret, val_Y[random_idx])\n",
    "    plt.title(\"Angle Error: {:.3f}\".format(compute_angle_error(val_Y[random_idx], ret)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3: Demo - Playground (0%)\n",
    "Visualize the gaze over an image directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gazelib.utils import download_demo_Img, load_demo_Img\n",
    "\n",
    "download_demo_Img()\n",
    "# You can have your own image at assignment_Gaze/dataset(comment download commend above), \n",
    "# the load_deomo_Img() will return first noncsv as an image back, with the support of most\n",
    "# formats of image\n",
    "demo_im = load_demo_Img()\n",
    "\n",
    "plt.imshow(demo_im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gazelib.demo import estimate_gaze\n",
    "from gazelib.task_3_judge import convert_to_unit_vector\n",
    "import numpy as np\n",
    "\n",
    "def eyeim2gaze(eye_im):\n",
    "    y_est = KNN(train_X, train_Y, eye_im, k=5)\n",
    "    \n",
    "    return convert_to_unit_vector(y_est)\n",
    "\n",
    "\n",
    "estimate_gaze(demo_im, eyeim2gaze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/good_job_banner.png)\n",
    "You should have completed **all cells(35%)** in this task locally when you reach here! You are able to build a data-driven gaze estimator.\n",
    "\n",
    "**CheckList**\n",
    "\n",
    "- KNN_idxs (10%)\n",
    "- oneNN (5%)\n",
    "- KNN (5%)\n",
    "- KNN_weighted (15%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
